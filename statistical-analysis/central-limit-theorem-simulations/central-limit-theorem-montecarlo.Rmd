---
title: "Central Limit Theorem - Monte Carlo"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


### clear working memory
```{r}
rm(list=ls())    
```

### loading libraries
```{r, echo=FALSE}
library('rmutil')
library("tidyverse")
```

```{r}
#Suppose that x is drawn from the following “mixing distribution.” Let y be a binary random variable with Pr(y = 1) = 0.9. If y = 1, then x is drawn from a standard normal distribution. If y = 0, then x is drawn from a normal distribution with mean = 100 and standard deviation  = 20. a) Find the mean of x. 

y <- ifelse(runif(100000) < 0.90, 1, 0)

x <- ifelse(y == 1, rnorm(100000), rnorm(100000, mean = 100, sd = 20))

print(paste("Mean of x: ", mean(x)))

```

```{r}

#b) For this distribution, use 10,000 draws from each of the following sample sizes: n = 36, n = 64, n = 100, n = 225, n = 2500, and n = 12100. Discuss how well the normal approximation fits your simulated estimates of the mean at the critical values of 0.025 and 0.975.

generate_simulated_means <- function(N){
   # Generate the mean and standard deviations of N observations from the specified distribution functions
  
   # y is a binary random variable with Pr(y = 1) = 0.9. 
   # If y = 1, then x is drawn from a standard normal distribution. 
   # If y = 0, then x is drawn from a normal distribution with mean = 100 and standard deviation  = 20.
   y <- ifelse(runif(N) < 0.90, 1, 0)
   x <- ifelse(y == 1, rnorm(N), rnorm(N, mean = 100, sd = 20))
   
   # put data into data_frame so it is easier to summarize
   data <- tibble(y, x)
   
   # get the means for each column 
   means <- sapply(data, mean)
   
   # name the means appropriately
   names(means) <- c("muy", "mux")
   
   # get the sds for each column
   sds <- sapply(data, sd)
    
   # name the sds appropriately
   names(sds) <- c("sdy", "sdx")
   
   # return the means and standard deviation associated with sample x of size N.
   return(c(means, sds))
   }



get_zscores <-function(obs_mean, true_mean, obs_sd, N){
  zscores <- (obs_mean - true_mean) / (obs_sd / sqrt(N))
  return( zscores ) 
}

significance_test <- function(zscores, alpha){
  beyond_critical_point <- as.numeric( zscores > alpha | zscores < -alpha ) 
  percent_significantly_different <- mean( beyond_critical_point )
  return( percent_significantly_different )
}



monte_carlo <- function(N, reps = 10000){

  replicated_sims <- replicate(reps, generate_simulated_means(N))
  
  expected_mu_y <- 0.9
  expected_mu_x <- 10 # Derived from 0.9*0 + 0.1*100
  

  z_y <- get_zscores(replicated_sims['muy', ], expected_mu_y, replicated_sims['sdy', ], N)
  
  
  sig1_y <- significance_test(z_y, 0.025)
  print(paste("Percentage of simulated means which were significantly different from"))
  print(paste("sampling distribution at critical point 0.025:", sig1_y))
  print(paste("                    "))
  
  sig2_y <- significance_test(z_y, 0.975)
  print(paste("Percentage of simulated means which were significantly different from"))
  print(paste("sampling distribution at critical point 0.975:", sig2_y))
  print(paste("                    "))
  

  
  z_x <- get_zscores(replicated_sims['mux', ], expected_mu_x, replicated_sims['sdx', ], N)
  
  
  sig1_x <- significance_test(z_x, 0.025)
  print(paste("Percentage of simulated means which were significantly different from"))
  print(paste("sampling distribution at critical point 0.025:", sig1_x))
  print(paste("                    "))
  
  sig2_x <- significance_test(z_x, 0.975)
  print(paste("Percentage of simulated means which were significantly different from"))
  print(paste("sampling distribution at critical point 0.975:", sig2_x))
  print(paste("                    "))

}

for (N in c(36, 64, 100, 225, 2500, 12100)){
  print(paste('Starting simulations with samples of size', N))
  monte_carlo(N, 10000)
  print('')
}




```




### Observations
###Central Limit theorem is interpreted here.
#a)Mean of the random variable 'x' following the 'Mixed distribution' = 10
#b)
#1. As we increase N, the percentage of sample means that have a z-score below -0.025 and above 0.025 is ~99%.
#2. For critical point z = 0.975: As we increase N, the percentage of sample means that have a z-score below -0.975 and above 0.975 is ~34%, which means 66% of the sample means are between z score of 0.975.
#These simulation results are in accordance with a typical normal distribution where almost 68% of sample means lie within a z-score of 1 and where many sample means fall outside the z-score of 0.025 as the interval defined by the same is very very small. 



